{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37beeda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55e2a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pickle\n",
    "import zipfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List\n",
    "from hyperopt.pyll import scope\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d944e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(url: str):\n",
    "    \"\"\"\n",
    "    Capital Bikeshare datasets are zipped\n",
    "    We need to download then extract the csv\n",
    "    \"\"\"\n",
    "    zip_path = url.split('/')[-1] \n",
    "    file_name = zip_path.split('.')[0] + '.csv'\n",
    "\n",
    "    req = requests.get(url)\n",
    "\n",
    "    with open(zip_path, 'wb') as f_out:\n",
    "        f_out.write(req.content)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        with z.open(file_name) as f:\n",
    "            df = pd.read_csv(f, parse_dates=True)\n",
    "            \n",
    "    categorical_cols = ['rideable_type', 'start_station_id', 'end_station_id']\n",
    "    date_cols = ['started_at', 'ended_at']\n",
    "    \n",
    "    df[categorical_cols] = df[categorical_cols].astype(str)\n",
    "    df[date_cols] = df[date_cols].apply(pd.to_datetime, format='%Y/%m/%d %H:%M:%S')\n",
    "    \n",
    "    df['duration'] = df['ended_at'] - df['started_at']\n",
    "    df['duration'] = df['duration'].apply(lambda x: round(x.total_seconds() / 60, 0))\n",
    "    df['start_end'] = df['start_station_id'] + '_' + df['end_station_id']\n",
    "\n",
    "    df = df[df['duration'] <= 120]\n",
    "\n",
    "    categorical_cols = ['rideable_type', 'start_end']\n",
    "    target = 'duration'\n",
    "    \n",
    "    return df, categorical_cols, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eece1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, categorical_cols, target = read_data('https://s3.amazonaws.com/capitalbikeshare-data/202204-capitalbikeshare-tripdata.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "904b1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_sets(df: pd.DataFrame, categorical_cols: List, target: str):\n",
    "    dv = DictVectorizer()\n",
    "    dicts = df[categorical_cols].to_dict(orient='records')\n",
    "    \n",
    "    x = dv.fit_transform(dicts)\n",
    "    y = df[target].values\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "    print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)\n",
    "    print(dv)\n",
    "\n",
    "    return x_train, x_val, y_train, y_val, dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "30a38fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243756, 54362) (60939, 54362) (243756,) (60939,)\n",
      "DictVectorizer()\n"
     ]
    }
   ],
   "source": [
    "# categorical_cols = ['rideable_type', 'start_end']\n",
    "# target = 'duration'\n",
    "x_train, x_val, y_train, y_val, dv = create_train_val_sets(df, categorical_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "57ebc2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.405431269954295"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = Ridge().fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_val)\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6bf96b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ridge.bin', 'wb') as f_out:\n",
    "    pickle.dump((dv, lr), f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "040ad33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = 'http://127.0.0.1:5000'\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0056572f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/1', experiment_id='1', lifecycle_stage='active', name='bikeshare-ride-duration-prediction', tags={}>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment('bikeshare-ride-duration-prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1895bb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243756, 54362) (60939, 54362) (243756,) (60939,)\n",
      "DictVectorizer()\n",
      "default artifacts URI: './mlruns/1/aee2c1513c1744329d41da48772c60bf/artifacts'\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    categorical_cols = ['rideable_type', 'start_end']\n",
    "    target = 'duration'\n",
    "    x_train, x_val, y_train, y_val, dv = create_train_val_sets(df, categorical_cols, target)\n",
    "\n",
    "    params = {\n",
    "        'alpha': 1,\n",
    "        'random_state': 0\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = Ridge(**params).fit(x_train, y_train)\n",
    "    y_pred = lr.predict(x_val)\n",
    "    mlflow.log_metric('mean_squared_error', mean_squared_error(y_val, y_pred, squared=False))\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, artifact_path='models')\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3d953481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(data_path, num_trials):\n",
    "    \n",
    "    df, categorical_cols, target = read_data(data_path)\n",
    "    x_train, x_val, y_train, y_val, dv = create_train_val_sets(df, categorical_cols, target)\n",
    "\n",
    "\n",
    "    def objective(params):\n",
    "\n",
    "        # rf = RandomForestRegressor(**params)\n",
    "        # rf.fit(x_train, y_train)\n",
    "        # y_pred = rf.predict(x_val)\n",
    "        # rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "        lr = Ridge(**params)\n",
    "        lr.fit(x_train, y_train)\n",
    "        y_pred = lr.predict(x_val)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "        return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "    # search_space = {\n",
    "    #     'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
    "    #     'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
    "    #     'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "    #     'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
    "    #     'random_state': 0\n",
    "    # }\n",
    "\n",
    "    search_space = {\n",
    "        'alpha': scope.int(hp.uniform('alpha', 0.1, 1))\n",
    "    }\n",
    "\n",
    "    rstate = np.random.default_rng(0)  # for reproducible results\n",
    "    best_result = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=num_trials,\n",
    "        trials=Trials(),\n",
    "        rstate=rstate\n",
    "    )\n",
    "\n",
    "    return best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "96ad3004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243756, 54362) (60939, 54362) (243756,) (60939,)\n",
      "DictVectorizer()\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.31trial/s, best loss: 14.5391502413888]\n"
     ]
    }
   ],
   "source": [
    "best_result = run(data_path='https://s3.amazonaws.com/capitalbikeshare-data/202204-capitalbikeshare-tripdata.zip', num_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7367243c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mlops')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "08fff7c61d7773b9095eefa104c355d3e759bf3b9ad7cd430a6345f664278925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
